{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace77cc4",
   "metadata": {},
   "source": [
    "# N-Gram Language models using python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dd6fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing  required Libraries\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "import random\n",
    "import math\n",
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b45d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ngrams(text, n):\n",
    "    \"\"\"\n",
    "    Generate n-grams (character-level) from a given text.\n",
    "    \n",
    "    Parameters:\n",
    "    text (str): Input text\n",
    "    n (int): Size of the n-grams\n",
    "    \n",
    "    Returns:\n",
    "    list: A list of n-grams as tuples\n",
    "    \"\"\"\n",
    "    #Added padding with '#' character to handle the start of sequences\n",
    "    padded_text ='#'*(n-1) +text\n",
    "    ngrams=[]\n",
    "    for i in range(len(padded_text) - n + 1):\n",
    "        ngram= tuple(padded_text[i:i+1])\n",
    "        ngrams.append(ngram)\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a98f7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character- Level Bigrams: [('#',), ('h',), ('e',), ('l',), ('l',), ('o',), (' ',), ('w',), ('o',), ('r',), ('l',)]\n"
     ]
    }
   ],
   "source": [
    "#Example Text\n",
    "text = \"hello world\"\n",
    "\n",
    "#Generate and display bigrams (2-grams)\n",
    "bigrams = generate_ngrams(text, 2)\n",
    "print(\"Character- Level Bigrams:\",bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dfb597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ngram_model(corpus, n):\n",
    "    \"\"\"\n",
    "    Build an n-grams language model from the corpus.\n",
    "    \n",
    "    Parameter:\n",
    "    corpus (str): Text corpus for building the model\n",
    "    n (int):Size of the n-grams\n",
    "    \n",
    "    Returns:\n",
    "    dict: A probability distribution for each context\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize the model\n",
    "    model = deafultdict(Counter)\n",
    "    \n",
    "    #Generate n-grams\n",
    "    ngrams = generate_ngrams(corpus,n)\n",
    "    \n",
    "    #Build the model\n",
    "    for ngram in ngrams:\n",
    "        context = ngram[:-1] #all but the last character\n",
    "        char = ngram[-1]     #the last character\n",
    "        model[context][char] +=1\n",
    "        \n",
    "    #convert counts to probabilties\n",
    "    for context in model:\n",
    "        total_count = sum(model[context].values())\n",
    "        for char in model[context]:\n",
    "            model[context][char] =model[context][char]/total_count\n",
    "            \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c144c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_smoothing(model, vocabulary_size,alpha = 1.0):\n",
    "    \"\"\"\n",
    "    Apply smoothing to an n-gram model.\n",
    "    \n",
    "    Parameters:\n",
    "    model (defaultdict): N-gram model.\n",
    "    vocabulary_size(int): Total number of unique character in the vocabulary\n",
    "    alpha (float): Smoothing parameter (default is 1.0).\n",
    "    \n",
    "    Returns:\n",
    "    defaultdict: Smoothed n-gram model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    smoothed_model = defaultdict(Counter)\n",
    "    for prefix, char_counts in model.items():\n",
    "        total_count = sum(char_counts.values())  + aplha * vocabulary_size\n",
    "        for char in char_counts:\n",
    "            smoothed_model[prefix][char] = (char_counts[char] + alpha)/total_counts\n",
    "        for char in range(vocabulary_size):\n",
    "            if char not in char_counts:\n",
    "                smoothed_model[prefix][char] = alpha /toatl_count\n",
    "    return smoothed_model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992bb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, n , strat_text, length=100):\n",
    "    \"\"\"\n",
    "    Generate text using the n-gram model.\n",
    "    \n",
    "    Parameters:\n",
    "    model (dict): Trained n-gram model\n",
    "    n(int) : Size of the n-grams\n",
    "    start_text (str): Initial text to strat generation\n",
    "    length (int): Number of character to generates\n",
    "    \n",
    "    Returns:\n",
    "    str: Generated text\n",
    "    \"\"\"\n",
    "    \n",
    "    #Initialize with start text\n",
    "    current_text = list(start_text)\n",
    "    \n",
    "    #Generate characters\n",
    "    for _ in range(length):\n",
    "        #get the current context\n",
    "        context = tuple(current_text[-(n-1):]) if len(current_text) >= n-1 else tuple('#' * (n-1 - len(current_text)) + ''.join(current_text))\n",
    "    \n",
    "    \n",
    "        #If context not in model, break\n",
    "        if context not in model:\n",
    "            break\n",
    "        \n",
    "        #Get probability distribution for next character\n",
    "        char_dist = model[context]\n",
    "    \n",
    "        #sample next character\n",
    "        chars, probs = zip(*char_dist.items())\n",
    "        next_char = random.choices(chars, weights=probs)[0]\n",
    "    \n",
    "        #Append to generated text\n",
    "        current_text.append(next_char)\n",
    "    return ''.join(current_text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0901b7e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8.7",
   "language": "python",
   "name": "python3.8.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
